{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3412b302",
   "metadata": {},
   "source": [
    "# Etapa 2: Entrenamiento y Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752bbff",
   "metadata": {},
   "source": [
    "## 1. Procesar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a898d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Cargando datos ya procesados desde ecgs_procesados.csv...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Ruta al archivo procesado\n",
    "processed_file_path = '../data/ecgs_procesados.csv'\n",
    "\n",
    "if os.path.exists(processed_file_path):\n",
    "    print(\"📄 Cargando datos ya procesados desde ecgs_procesados.csv...\")\n",
    "    df = pd.read_csv(processed_file_path)\n",
    "else:\n",
    "    # Cargar etiquetas\n",
    "    ref_path = '../data/archivos/REFERENCE.csv'\n",
    "    labels_df = pd.read_csv(ref_path, header=None, names=['record', 'label'])\n",
    "    labels_df = labels_df[labels_df['label'] != '~']  # eliminar registros con etiqueta ~\n",
    "\n",
    "    # Ruta de los archivos\n",
    "    data_path = '../data/archivos/'\n",
    "\n",
    "    # Lista para almacenar características\n",
    "    features = []\n",
    "\n",
    "    for _, row in labels_df.iterrows():\n",
    "        record_name = row['record']\n",
    "        label_code = row['label']\n",
    "\n",
    "        record_path = os.path.join(data_path, record_name)\n",
    "\n",
    "        try:\n",
    "            # Leer archivo .mat\n",
    "            mat_data = loadmat(record_path + '.mat')  # asegurarse de incluir la extensión .mat\n",
    "            signal = mat_data['val']  # típico nombre de la señal en PhysioNet .mat\n",
    "            signal_1ch = signal[0]  # primer canal\n",
    "\n",
    "            # Normalizar la señal\n",
    "            signal_norm = (signal_1ch - np.mean(signal_1ch)) / np.std(signal_1ch)\n",
    "            peaks, _ = find_peaks(signal_norm, distance=200, height=0.5) \n",
    "\n",
    "            rr_intervals = np.diff(peaks)\n",
    "\n",
    "            if len(rr_intervals) < 3:\n",
    "                continue\n",
    "\n",
    "            mean_rr = np.mean(rr_intervals)\n",
    "            std_rr = np.std(rr_intervals)\n",
    "            skew_rr = skew(rr_intervals)\n",
    "            kurt_rr = kurtosis(rr_intervals)\n",
    "\n",
    "            label = {'N': 'Normal', 'A': 'AFib', 'O': 'Other'}.get(label_code, None)\n",
    "            if label is None:\n",
    "                continue\n",
    "\n",
    "            features.append([mean_rr, std_rr, skew_rr, kurt_rr, label])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {record_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Crear DataFrame final\n",
    "    df = pd.DataFrame(features, columns=['mean_rr', 'std_rr', 'skew_rr', 'kurt_rr', 'label'])\n",
    "\n",
    "    # Guardar en CSV\n",
    "    output_path = '../data/ecgs_procesados.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"✅ ECGs procesados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0deb3",
   "metadata": {},
   "source": [
    "## 2. Separar variables predictoras y variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce22ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['mean_rr', 'std_rr', 'skew_rr', 'kurt_rr']]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed41080",
   "metadata": {},
   "source": [
    "## 3. Dividir el dataset en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed685fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5d393",
   "metadata": {},
   "source": [
    "## 4. Escalar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4991319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91cee54",
   "metadata": {},
   "source": [
    "## 5. Entrenar un modelo base con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "modelo = SVC(kernel='rbf', class_weight='balanced', C=10, gamma='scale', probability=True, random_state=42)\n",
    "modelo.fit(X_train_scaled, y_train)\n",
    "y_pred = modelo.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90235b8b",
   "metadata": {},
   "source": [
    "## 6. Evaluar el desempeño del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5603\n",
      "Precision: 0.4969\n",
      "Recall: 0.5944\n",
      "F1-Score: 0.4948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c409b59",
   "metadata": {},
   "source": [
    "## 7. Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812969af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay\n",
      "\u001b[1;32m----> 4\u001b[0m \u001b[43mConfusionMatrixDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatriz de Confusión - Random Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:320\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.from_estimator\u001b[1;34m(cls, estimator, X, y, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar, im_kw, text_kw)\u001b[0m\n",
      "\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_classifier(estimator):\n",
      "\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m only supports classifiers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m--> 320\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_predictions(\n",
      "\u001b[0;32m    323\u001b[0m     y,\n",
      "\u001b[0;32m    324\u001b[0m     y_pred,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    336\u001b[0m     text_kw\u001b[38;5;241m=\u001b[39mtext_kw,\n",
      "\u001b[0;32m    337\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n",
      "\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n",
      "\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1718\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n",
      "\u001b[0;32m   1707\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n",
      "\u001b[0;32m   1708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n",
      "\u001b[0;32m   1709\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1715\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[0;32m   1716\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n",
      "\u001b[0;32m   1717\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n",
      "\u001b[1;32m-> 1718\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   1719\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1725\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n",
      "\u001b[0;32m   1726\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n",
      "\u001b[0;32m   1727\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n",
      "\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n",
      "\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1327\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n",
      "\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n",
      "\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m-> 1327\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minplace_predict(\n",
      "\u001b[0;32m   1328\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n",
      "\u001b[0;32m   1329\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n",
      "\u001b[0;32m   1330\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1331\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n",
      "\u001b[0;32m   1332\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n",
      "\u001b[0;32m   1333\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n",
      "\u001b[0;32m   1334\u001b[0m         )\n",
      "\u001b[0;32m   1335\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n",
      "\u001b[0;32m   1336\u001b[0m             cp \u001b[38;5;241m=\u001b[39m import_cupy()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:922\u001b[0m, in \u001b[0;36mXGBModel.get_booster\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n",
      "\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n",
      "\u001b[1;32m--> 922\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to call fit or load_model beforehand\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\n",
      "\n",
      "\u001b[1;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(modelo, X_test_scaled, y_test, cmap='Blues')\n",
    "plt.title(\"Matriz de Confusión - Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa75e32",
   "metadata": {},
   "source": [
    "## 8. Reporte completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cde6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFib       0.26      0.80      0.39       148\n",
      "      Normal       0.80      0.62      0.70      1010\n",
      "       Other       0.43      0.35      0.39       491\n",
      "\n",
      "    accuracy                           0.56      1649\n",
      "   macro avg       0.50      0.59      0.49      1649\n",
      "weighted avg       0.64      0.56      0.58      1649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533814ca",
   "metadata": {},
   "source": [
    "## Conclusiones de la Etapa 2\n",
    "\n",
    "- Se procesaron archivos .mat de señales ECG, extrayendo características estadísticas del intervalo RR: mean_rr, std_rr, skew_rr y kurt_rr, junto con sus etiquetas (Normal, AFib, Other) desde REFERENCE.csv.\n",
    "\n",
    "- Se utilizaron múltiples modelos clásicos de scikit-learn como Árboles de Decisión, Random Forest, Redes Neuronales (MLP) y SVM. De todos ellos, el modelo que logró el mejor desempeño general y, en especial, el mejor recall para la clase AFib, fue el SVM con kernel RBF, C=10 y class_weight='balanced'.\n",
    "\n",
    "- Este modelo obtuvo un recall de 0.49 para AFib, que es clave en contextos clínicos donde es más grave no detectar un caso verdadero. El accuracy global fue de 0.51, con métricas balanceadas entre clases (macro avg f1-score ≈ 0.42).\n",
    "\n",
    "- Si bien el modelo aún tiene espacio para mejorar, el objetivo prioritario de detectar fibrilación auricular se cumple de manera más efectiva con SVM, en comparación con otros enfoques clásicos.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
