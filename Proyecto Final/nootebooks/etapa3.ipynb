{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3412b302",
   "metadata": {},
   "source": [
    "# Etapa 2: Entrenamiento y Evaluaci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752bbff",
   "metadata": {},
   "source": [
    "## 1. Procesar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a898d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Cargando datos ya procesados desde ecgs_procesados.csv...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Ruta al archivo procesado\n",
    "processed_file_path = '../data/ecgs_procesados.csv'\n",
    "\n",
    "if os.path.exists(processed_file_path):\n",
    "    print(\"üìÑ Cargando datos ya procesados desde ecgs_procesados.csv...\")\n",
    "    df = pd.read_csv(processed_file_path)\n",
    "else:\n",
    "    # Cargar etiquetas\n",
    "    ref_path = '../data/archivos/REFERENCE.csv'\n",
    "    labels_df = pd.read_csv(ref_path, header=None, names=['record', 'label'])\n",
    "    labels_df = labels_df[labels_df['label'] != '~']  # eliminar registros con etiqueta ~\n",
    "\n",
    "    # Ruta de los archivos\n",
    "    data_path = '../data/archivos/'\n",
    "\n",
    "    # Lista para almacenar caracter√≠sticas\n",
    "    features = []\n",
    "\n",
    "    for _, row in labels_df.iterrows():\n",
    "        record_name = row['record']\n",
    "        label_code = row['label']\n",
    "\n",
    "        record_path = os.path.join(data_path, record_name)\n",
    "\n",
    "        try:\n",
    "            # Leer archivo .mat\n",
    "            mat_data = loadmat(record_path + '.mat')  # asegurarse de incluir la extensi√≥n .mat\n",
    "            signal = mat_data['val']  # t√≠pico nombre de la se√±al en PhysioNet .mat\n",
    "            signal_1ch = signal[0]  # primer canal\n",
    "\n",
    "            # Normalizar la se√±al\n",
    "            signal_norm = (signal_1ch - np.mean(signal_1ch)) / np.std(signal_1ch)\n",
    "            peaks, _ = find_peaks(signal_norm, distance=200, height=0.5) \n",
    "\n",
    "            rr_intervals = np.diff(peaks)\n",
    "\n",
    "            if len(rr_intervals) < 3:\n",
    "                continue\n",
    "\n",
    "            mean_rr = np.mean(rr_intervals)\n",
    "            std_rr = np.std(rr_intervals)\n",
    "            skew_rr = skew(rr_intervals)\n",
    "            kurt_rr = kurtosis(rr_intervals)\n",
    "\n",
    "            label = {'N': 'Normal', 'A': 'AFib', 'O': 'Other'}.get(label_code, None)\n",
    "            if label is None:\n",
    "                continue\n",
    "\n",
    "            features.append([mean_rr, std_rr, skew_rr, kurt_rr, label])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {record_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Crear DataFrame final\n",
    "    df = pd.DataFrame(features, columns=['mean_rr', 'std_rr', 'skew_rr', 'kurt_rr', 'label'])\n",
    "\n",
    "    # Guardar en CSV\n",
    "    output_path = '../data/ecgs_procesados.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"‚úÖ ECGs procesados guardados en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0deb3",
   "metadata": {},
   "source": [
    "## 2. Separar variables predictoras y variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce22ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['mean_rr', 'std_rr', 'skew_rr', 'kurt_rr']]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed41080",
   "metadata": {},
   "source": [
    "## 3. Dividir el dataset en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed685fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5d393",
   "metadata": {},
   "source": [
    "## 4. Escalar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4991319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91cee54",
   "metadata": {},
   "source": [
    "## 5. Entrenar un modelo base con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "modelo = SVC(kernel='rbf', class_weight='balanced', C=10, gamma='scale', probability=True, random_state=42)\n",
    "modelo.fit(X_train_scaled, y_train)\n",
    "y_pred = modelo.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90235b8b",
   "metadata": {},
   "source": [
    "## 6. Evaluar el desempe√±o del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5603\n",
      "Precision: 0.4969\n",
      "Recall: 0.5944\n",
      "F1-Score: 0.4948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c409b59",
   "metadata": {},
   "source": [
    "## 7. Matriz de confusi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812969af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay\n",
      "\u001b[1;32m----> 4\u001b[0m \u001b[43mConfusionMatrixDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatriz de Confusi√≥n - Random Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:320\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.from_estimator\u001b[1;34m(cls, estimator, X, y, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar, im_kw, text_kw)\u001b[0m\n",
      "\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_classifier(estimator):\n",
      "\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m only supports classifiers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m--> 320\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_predictions(\n",
      "\u001b[0;32m    323\u001b[0m     y,\n",
      "\u001b[0;32m    324\u001b[0m     y_pred,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    336\u001b[0m     text_kw\u001b[38;5;241m=\u001b[39mtext_kw,\n",
      "\u001b[0;32m    337\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n",
      "\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n",
      "\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1718\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n",
      "\u001b[0;32m   1707\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n",
      "\u001b[0;32m   1708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n",
      "\u001b[0;32m   1709\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1715\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[0;32m   1716\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n",
      "\u001b[0;32m   1717\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n",
      "\u001b[1;32m-> 1718\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   1719\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1725\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n",
      "\u001b[0;32m   1726\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n",
      "\u001b[0;32m   1727\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n",
      "\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n",
      "\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1327\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n",
      "\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n",
      "\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m-> 1327\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minplace_predict(\n",
      "\u001b[0;32m   1328\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n",
      "\u001b[0;32m   1329\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n",
      "\u001b[0;32m   1330\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m   1331\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n",
      "\u001b[0;32m   1332\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n",
      "\u001b[0;32m   1333\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n",
      "\u001b[0;32m   1334\u001b[0m         )\n",
      "\u001b[0;32m   1335\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n",
      "\u001b[0;32m   1336\u001b[0m             cp \u001b[38;5;241m=\u001b[39m import_cupy()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\yanko\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:922\u001b[0m, in \u001b[0;36mXGBModel.get_booster\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n",
      "\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n",
      "\u001b[1;32m--> 922\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to call fit or load_model beforehand\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\n",
      "\n",
      "\u001b[1;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(modelo, X_test_scaled, y_test, cmap='Blues')\n",
    "plt.title(\"Matriz de Confusi√≥n - Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa75e32",
   "metadata": {},
   "source": [
    "## 8. Reporte completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cde6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AFib       0.26      0.80      0.39       148\n",
      "      Normal       0.80      0.62      0.70      1010\n",
      "       Other       0.43      0.35      0.39       491\n",
      "\n",
      "    accuracy                           0.56      1649\n",
      "   macro avg       0.50      0.59      0.49      1649\n",
      "weighted avg       0.64      0.56      0.58      1649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nReporte de Clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533814ca",
   "metadata": {},
   "source": [
    "## Conclusiones de la Etapa 2\n",
    "\n",
    "- Se procesaron archivos .mat de se√±ales ECG, extrayendo caracter√≠sticas estad√≠sticas del intervalo RR: mean_rr, std_rr, skew_rr y kurt_rr, junto con sus etiquetas (Normal, AFib, Other) desde REFERENCE.csv.\n",
    "\n",
    "- Se utilizaron m√∫ltiples modelos cl√°sicos de scikit-learn como √Årboles de Decisi√≥n, Random Forest, Redes Neuronales (MLP) y SVM. De todos ellos, el modelo que logr√≥ el mejor desempe√±o general y, en especial, el mejor recall para la clase AFib, fue el SVM con kernel RBF, C=10 y class_weight='balanced'.\n",
    "\n",
    "- Este modelo obtuvo un recall de 0.49 para AFib, que es clave en contextos cl√≠nicos donde es m√°s grave no detectar un caso verdadero. El accuracy global fue de 0.51, con m√©tricas balanceadas entre clases (macro avg f1-score ‚âà 0.42).\n",
    "\n",
    "- Si bien el modelo a√∫n tiene espacio para mejorar, el objetivo prioritario de detectar fibrilaci√≥n auricular se cumple de manera m√°s efectiva con SVM, en comparaci√≥n con otros enfoques cl√°sicos.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
